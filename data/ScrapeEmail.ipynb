{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7988158",
   "metadata": {},
   "source": [
    "## Scrape Inbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e1b42",
   "metadata": {},
   "source": [
    "## Scrape Indiv Email with Forwarded Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b02cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date From   To  Cycle  Gas Days  Gas Hours Distillates Days  \\\n",
      "0  2025-08-26  HTN  GBJ     48         8          3                9   \n",
      "1  2025-08-26  HTN  GBJ     49         8         20               10   \n",
      "2  2025-08-25  HTN  GBJ     48         8          1                9   \n",
      "3  2025-08-24  HTN  GBJ     47         8         20                7   \n",
      "4  2025-08-24  HTN  GBJ     48         8          1               10   \n",
      "\n",
      "  Distillates Hours  \n",
      "0                 1  \n",
      "1                12  \n",
      "2                13  \n",
      "3                 8  \n",
      "4                21   \n",
      "[rows: 354]\n"
     ]
    }
   ],
   "source": [
    "import re, warnings\n",
    "import pandas as pd\n",
    "import win32com.client\n",
    "from io import StringIO\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TARGET_SUBJ = \"T4 Bulletin: Colonial - TRANSIT TIMES sent to sto_susan\"\n",
    "\n",
    "def _soup(html):\n",
    "    try:    return BeautifulSoup(html, \"lxml\")\n",
    "    except: return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "def _date_from_text(text, fallback):\n",
    "    try:\n",
    "        if \"Date:\" in text:\n",
    "            part = text.split(\"Date:\", 1)[1].split(\"\\n\", 1)[0]\n",
    "            return parser.parse(part, fuzzy=True).date() - timedelta(days=1)\n",
    "        return parser.parse(text, fuzzy=True).date() - timedelta(days=1)\n",
    "    except Exception:\n",
    "        return fallback - timedelta(days=1)\n",
    "\n",
    "def _promote_header(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Make the first row containing From & To the header\n",
    "    for i in range(min(8, len(df))):\n",
    "        vals = [str(v).strip().lower() for v in df.iloc[i].values]\n",
    "        if \"from\" in vals and \"to\" in vals:\n",
    "            df.columns = df.iloc[i].astype(str).str.strip()\n",
    "            return df.iloc[i+1:].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _norm_code(s):\n",
    "    return re.sub(r\"[^A-Z]\", \"\", str(s).upper())\n",
    "\n",
    "def _first_four_numbers_right_of(df, row_idx, start_col_idx):\n",
    "    \"\"\"Scan a row from start_col_idx+1 to the end; return first four ints.\"\"\"\n",
    "    nums = []\n",
    "    for x in df.iloc[row_idx, start_col_idx+1:].tolist():\n",
    "        try:\n",
    "            v = pd.to_numeric(str(x).strip(), errors=\"coerce\")\n",
    "        except Exception:\n",
    "            v = pd.NA\n",
    "        if pd.notna(v):\n",
    "            # keep only whole numbers (these fields are all integers)\n",
    "            if float(v).is_integer():\n",
    "                nums.append(int(v))\n",
    "        if len(nums) >= 4:  # Gas D, Gas H, Dist D, Dist H\n",
    "            break\n",
    "    while len(nums) < 4:\n",
    "        nums.append(pd.NA)\n",
    "    return nums  # [gd, gh, dd, dh]\n",
    "\n",
    "def extract_colonial_data():\n",
    "    ns = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "    inbox = ns.GetDefaultFolder(6)\n",
    "    items = inbox.Items\n",
    "    items.Sort(\"[ReceivedTime]\", True)\n",
    "\n",
    "    out_rows = []\n",
    "\n",
    "    for msg in items:\n",
    "        subj = (getattr(msg, \"Subject\", \"\") or \"\")\n",
    "        if TARGET_SUBJ not in subj:\n",
    "            continue\n",
    "\n",
    "        html = (getattr(msg, \"HTMLBody\", \"\") or \"\")\n",
    "        if not html:\n",
    "            continue\n",
    "\n",
    "        soup = _soup(html)\n",
    "        text = soup.get_text(\"\\n\", strip=True)\n",
    "        day = _date_from_text(text, msg.ReceivedTime.date())\n",
    "\n",
    "        for t in soup.find_all(\"table\"):\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "                try:\n",
    "                    dfs = pd.read_html(StringIO(str(t)))\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            for df in dfs:\n",
    "                if df.empty:\n",
    "                    continue\n",
    "\n",
    "                df = _promote_header(df)\n",
    "\n",
    "                # locate indices of From/To/Cycle (by name contains)\n",
    "                cols = [str(c).strip() for c in df.columns]\n",
    "                low  = [c.lower() for c in cols]\n",
    "                try: i_from  = next(i for i,c in enumerate(low) if c == \"from\")\n",
    "                except StopIteration: i_from = None\n",
    "                try: i_to    = next(i for i,c in enumerate(low) if c == \"to\")\n",
    "                except StopIteration: i_to = None\n",
    "                try: i_cycle = next((i for i,c in enumerate(low) if \"cycle\" in c), None)\n",
    "                except StopIteration: i_cycle = None\n",
    "                if i_from is None or i_to is None:\n",
    "                    continue\n",
    "\n",
    "                # clean codes\n",
    "                df[\"From\"] = df.iloc[:, i_from].map(_norm_code)\n",
    "                df[\"To\"]   = df.iloc[:, i_to].map(_norm_code)\n",
    "\n",
    "                # pick the column to start scanning numbers from\n",
    "                start_idx = i_cycle if i_cycle is not None else max(i_from, i_to)\n",
    "\n",
    "                # filter HTN -> GBJ rows and extract numbers\n",
    "                mask = (df[\"From\"] == \"HTN\") & (df[\"To\"] == \"GBJ\")\n",
    "                for ridx in df.index[mask]:\n",
    "                    gd, gh, dd, dh = _first_four_numbers_right_of(df, ridx, start_idx)\n",
    "\n",
    "                    # cycle (integer if present)\n",
    "                    cyc = pd.NA\n",
    "                    if i_cycle is not None:\n",
    "                        try:\n",
    "                            cyc = pd.to_numeric(df.iat[ridx, i_cycle], errors=\"coerce\")\n",
    "                            if pd.notna(cyc) and float(cyc).is_integer():\n",
    "                                cyc = int(cyc)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                    out_rows.append({\n",
    "                        \"Date\": day,\n",
    "                        \"From\": \"HTN\",\n",
    "                        \"To\": \"GBJ\",\n",
    "                        \"Cycle\": cyc,\n",
    "                        \"Gas Days\": gd, \"Gas Hours\": gh,\n",
    "                        \"Distillates Days\": dd, \"Distillates Hours\": dh\n",
    "                    })\n",
    "\n",
    "    if not out_rows:\n",
    "        return pd.DataFrame(columns=[\"Date\",\"From\",\"To\",\"Cycle\",\"Gas Days\",\"Gas Hours\",\"Distillates Days\",\"Distillates Hours\"])\n",
    "\n",
    "    out = (pd.DataFrame(out_rows)\n",
    "             .sort_values(\"Date\", ascending=False)\n",
    "             .reset_index(drop=True))\n",
    "    return out\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = extract_colonial_data()\n",
    "    # df.to_excel(\"ColonialTransitTimes_Line3.xlsx\", index=False)\n",
    "    print(df.head(), f\"\\n[rows: {len(df)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf94abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Colonial Pipeline transit times (HTN -> GBJ)...\n",
      "\n",
      "Extracted 354 records:\n",
      "         Date From   To  Cycle  Gas Days  Gas Hours Distillates Days  \\\n",
      "0  2025-08-26  HTN  GBJ     48         8          3                9   \n",
      "1  2025-08-26  HTN  GBJ     49         8         20               10   \n",
      "2  2025-08-25  HTN  GBJ     48         8          1                9   \n",
      "3  2025-08-24  HTN  GBJ     47         8         20                7   \n",
      "4  2025-08-24  HTN  GBJ     48         8          1               10   \n",
      "\n",
      "  Distillates Hours  \n",
      "0                 1  \n",
      "1                12  \n",
      "2                13  \n",
      "3                 8  \n",
      "4                21  \n",
      "\n",
      "==================================================\n",
      "Example with custom locations (you can modify these):\n",
      "df = extract_colonial_transit_times('ABC', 'XYZ')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Colonial Pipeline Transit Times Data Extractor\n",
    "\n",
    "Extracts transit time data from Outlook emails containing Colonial Pipeline bulletins.\n",
    "Supports configurable From/To location parameters.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import win32com.client\n",
    "from io import StringIO\n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Optional, Tuple, List, Dict, Any\n",
    "\n",
    "\n",
    "class ColonialTransitExtractor:\n",
    "    \"\"\"Extracts Colonial Pipeline transit time data from Outlook emails.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_subject: str = \"T4 Bulletin: Colonial - TRANSIT TIMES sent to sto_susan\"):\n",
    "        \"\"\"\n",
    "        Initialize the extractor.\n",
    "        \n",
    "        Args:\n",
    "            target_subject: Email subject line to search for\n",
    "        \"\"\"\n",
    "        self.target_subject = target_subject\n",
    "    \n",
    "    def _create_soup(self, html: str) -> BeautifulSoup:\n",
    "        \"\"\"Create BeautifulSoup object with fallback parsers.\"\"\"\n",
    "        try:\n",
    "            return BeautifulSoup(html, \"lxml\")\n",
    "        except:\n",
    "            return BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    def _extract_date_from_text(self, text: str, fallback_date) -> Any:\n",
    "        \"\"\"Extract date from email text with fallback.\"\"\"\n",
    "        try:\n",
    "            if \"Date:\" in text:\n",
    "                date_part = text.split(\"Date:\", 1)[1].split(\"\\n\", 1)[0]\n",
    "                return parser.parse(date_part, fuzzy=True).date() - timedelta(days=1)\n",
    "            return parser.parse(text, fuzzy=True).date() - timedelta(days=1)\n",
    "        except Exception:\n",
    "            return fallback_date - timedelta(days=1)\n",
    "    \n",
    "    def _promote_header_row(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Find and promote the row containing 'From' and 'To' as column headers.\"\"\"\n",
    "        for i in range(min(8, len(df))):\n",
    "            values = [str(v).strip().lower() for v in df.iloc[i].values]\n",
    "            if \"from\" in values and \"to\" in values:\n",
    "                df.columns = df.iloc[i].astype(str).str.strip()\n",
    "                return df.iloc[i+1:].reset_index(drop=True)\n",
    "        return df\n",
    "    \n",
    "    def _normalize_location_code(self, code: str) -> str:\n",
    "        \"\"\"Normalize location code by keeping only uppercase letters.\"\"\"\n",
    "        return re.sub(r\"[^A-Z]\", \"\", str(code).upper())\n",
    "    \n",
    "    def _extract_first_four_numbers(self, df: pd.DataFrame, row_idx: int, start_col_idx: int) -> List[Any]:\n",
    "        \"\"\"\n",
    "        Extract the first four numeric values from a row starting from start_col_idx+1.\n",
    "        \n",
    "        Returns:\n",
    "            List of four values: [gas_days, gas_hours, distillates_days, distillates_hours]\n",
    "        \"\"\"\n",
    "        numbers = []\n",
    "        for value in df.iloc[row_idx, start_col_idx+1:].tolist():\n",
    "            try:\n",
    "                numeric_val = pd.to_numeric(str(value).strip(), errors=\"coerce\")\n",
    "            except Exception:\n",
    "                numeric_val = pd.NA\n",
    "            \n",
    "            if pd.notna(numeric_val) and float(numeric_val).is_integer():\n",
    "                numbers.append(int(numeric_val))\n",
    "            \n",
    "            if len(numbers) >= 4:  # Gas Days, Gas Hours, Distillates Days, Distillates Hours\n",
    "                break\n",
    "        \n",
    "        # Pad with NA values if we don't have 4 numbers\n",
    "        while len(numbers) < 4:\n",
    "            numbers.append(pd.NA)\n",
    "        \n",
    "        return numbers\n",
    "    \n",
    "    def _find_column_indices(self, df: pd.DataFrame) -> Tuple[Optional[int], Optional[int], Optional[int]]:\n",
    "        \"\"\"Find column indices for From, To, and Cycle columns.\"\"\"\n",
    "        columns = [str(c).strip() for c in df.columns]\n",
    "        lowercase_cols = [c.lower() for c in columns]\n",
    "        \n",
    "        try:\n",
    "            from_idx = next(i for i, c in enumerate(lowercase_cols) if c == \"from\")\n",
    "        except StopIteration:\n",
    "            from_idx = None\n",
    "        \n",
    "        try:\n",
    "            to_idx = next(i for i, c in enumerate(lowercase_cols) if c == \"to\")\n",
    "        except StopIteration:\n",
    "            to_idx = None\n",
    "        \n",
    "        try:\n",
    "            cycle_idx = next((i for i, c in enumerate(lowercase_cols) if \"cycle\" in c), None)\n",
    "        except StopIteration:\n",
    "            cycle_idx = None\n",
    "        \n",
    "        return from_idx, to_idx, cycle_idx\n",
    "    \n",
    "    def _extract_cycle_value(self, df: pd.DataFrame, row_idx: int, cycle_col_idx: Optional[int]) -> Any:\n",
    "        \"\"\"Extract and validate cycle value from the specified column.\"\"\"\n",
    "        if cycle_col_idx is None:\n",
    "            return pd.NA\n",
    "        \n",
    "        try:\n",
    "            cycle_val = pd.to_numeric(df.iat[row_idx, cycle_col_idx], errors=\"coerce\")\n",
    "            if pd.notna(cycle_val) and float(cycle_val).is_integer():\n",
    "                return int(cycle_val)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return pd.NA\n",
    "    \n",
    "    def extract_transit_data(self, from_location: str = \"HTN\", to_location: str = \"GBJ\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract Colonial Pipeline transit time data from Outlook emails.\n",
    "        \n",
    "        Args:\n",
    "            from_location: Source location code (default: \"HTN\")\n",
    "            to_location: Destination location code (default: \"GBJ\")\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with columns: Date, From, To, Cycle, Gas Days, Gas Hours, \n",
    "                                  Distillates Days, Distillates Hours\n",
    "        \"\"\"\n",
    "        # Normalize location codes\n",
    "        from_code = self._normalize_location_code(from_location)\n",
    "        to_code = self._normalize_location_code(to_location)\n",
    "        \n",
    "        # Connect to Outlook\n",
    "        try:\n",
    "            outlook = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "            namespace = outlook.GetNamespace(\"MAPI\")\n",
    "            inbox = namespace.GetDefaultFolder(6)  # Inbox folder\n",
    "            items = inbox.Items\n",
    "            items.Sort(\"[ReceivedTime]\", True)  # Sort by received time, descending\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to connect to Outlook: {e}\")\n",
    "        \n",
    "        extracted_data = []\n",
    "        \n",
    "        # Process each email\n",
    "        for message in items:\n",
    "            subject = getattr(message, \"Subject\", \"\") or \"\"\n",
    "            if self.target_subject not in subject:\n",
    "                continue\n",
    "            \n",
    "            html_body = getattr(message, \"HTMLBody\", \"\") or \"\"\n",
    "            if not html_body:\n",
    "                continue\n",
    "            \n",
    "            # Parse HTML and extract date\n",
    "            soup = self._create_soup(html_body)\n",
    "            text_content = soup.get_text(\"\\n\", strip=True)\n",
    "            email_date = self._extract_date_from_text(text_content, message.ReceivedTime.date())\n",
    "            \n",
    "            # Process all tables in the email\n",
    "            for table in soup.find_all(\"table\"):\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "                    try:\n",
    "                        dataframes = pd.read_html(StringIO(str(table)))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                \n",
    "                # Process each DataFrame from the table\n",
    "                for df in dataframes:\n",
    "                    if df.empty:\n",
    "                        continue\n",
    "                    \n",
    "                    # Promote header row\n",
    "                    df = self._promote_header_row(df)\n",
    "                    \n",
    "                    # Find column indices\n",
    "                    from_idx, to_idx, cycle_idx = self._find_column_indices(df)\n",
    "                    if from_idx is None or to_idx is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Clean location codes\n",
    "                    df[\"From\"] = df.iloc[:, from_idx].map(self._normalize_location_code)\n",
    "                    df[\"To\"] = df.iloc[:, to_idx].map(self._normalize_location_code)\n",
    "                    \n",
    "                    # Determine starting column for number extraction\n",
    "                    start_col_idx = cycle_idx if cycle_idx is not None else max(from_idx, to_idx)\n",
    "                    \n",
    "                    # Filter rows matching the specified route\n",
    "                    route_mask = (df[\"From\"] == from_code) & (df[\"To\"] == to_code)\n",
    "                    matching_rows = df.index[route_mask]\n",
    "                    \n",
    "                    # Extract data from matching rows\n",
    "                    for row_idx in matching_rows:\n",
    "                        gas_days, gas_hours, dist_days, dist_hours = self._extract_first_four_numbers(\n",
    "                            df, row_idx, start_col_idx\n",
    "                        )\n",
    "                        \n",
    "                        cycle_value = self._extract_cycle_value(df, row_idx, cycle_idx)\n",
    "                        \n",
    "                        extracted_data.append({\n",
    "                            \"Date\": email_date,\n",
    "                            \"From\": from_code,\n",
    "                            \"To\": to_code,\n",
    "                            \"Cycle\": cycle_value,\n",
    "                            \"Gas Days\": gas_days,\n",
    "                            \"Gas Hours\": gas_hours,\n",
    "                            \"Distillates Days\": dist_days,\n",
    "                            \"Distillates Hours\": dist_hours\n",
    "                        })\n",
    "        \n",
    "        # Create final DataFrame\n",
    "        if not extracted_data:\n",
    "            return pd.DataFrame(columns=[\n",
    "                \"Date\", \"From\", \"To\", \"Cycle\", \"Gas Days\", \"Gas Hours\", \n",
    "                \"Distillates Days\", \"Distillates Hours\"\n",
    "            ])\n",
    "        \n",
    "        result_df = (pd.DataFrame(extracted_data)\n",
    "                    .sort_values(\"Date\", ascending=False)\n",
    "                    .reset_index(drop=True))\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "\n",
    "def extract_colonial_transit_times(from_location: str = \"HTN\", \n",
    "                                 to_location: str = \"GBJ\",\n",
    "                                 target_subject: str = \"T4 Bulletin: Colonial - TRANSIT TIMES sent to sto_susan\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convenience function to extract Colonial Pipeline transit time data.\n",
    "    \n",
    "    Args:\n",
    "        from_location: Source location code (default: \"HTN\")\n",
    "        to_location: Destination location code (default: \"GBJ\")\n",
    "        target_subject: Email subject line to search for\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with transit time data\n",
    "    \"\"\"\n",
    "    extractor = ColonialTransitExtractor(target_subject)\n",
    "    return extractor.extract_transit_data(from_location, to_location)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for command-line usage.\"\"\"\n",
    "    # Example usage with default parameters (HTN -> GBJ)\n",
    "    print(\"Extracting Colonial Pipeline transit times (HTN -> GBJ)...\")\n",
    "    df = extract_colonial_transit_times()\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(f\"\\nExtracted {len(df)} records:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Optionally save to Excel\n",
    "        # df.to_excel(\"ColonialTransitTimes_HTN_to_GBJ.xlsx\", index=False)\n",
    "        # print(\"\\nData saved to ColonialTransitTimes_HTN_to_GBJ.xlsx\")\n",
    "    else:\n",
    "        print(\"No data found matching the criteria.\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('my_env311')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ff7a2407abc892812ad7b31944b1fdaa11dbd950ee9f1c2a56b01093e4d5b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
